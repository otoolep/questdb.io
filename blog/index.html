<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Blog · QuestDB</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Always on time"/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Blog · QuestDB"/><meta property="og:type" content="website"/><meta property="og:url" content="https://questdb.io/"/><meta property="og:description" content="Always on time"/><meta property="og:image" content="https://questdb.io/img/favicon.png"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://questdb.io/img/favicon.png"/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://questdb.io/blog/atom.xml" title="QuestDB Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://questdb.io/blog/feed.xml" title="QuestDB Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-145747842-1', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600,700|Source+Code+Pro:400,700|Open+Sans:300,400,600,700"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/code-block-buttons.js"></script><script type="text/javascript" src="/js/getstarted.js"></script><script type="text/javascript" src="/js/signup.js"></script><script type="text/javascript" src="/js/hotjar.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="blog"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/QuestDB_Logo.png" alt="QuestDB"/><h2 class="headerTitleWithLogo">QuestDB</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/" target="_self">Home</a></li><li class=""><a href="/getstarted" target="_self">Get QuestDB</a></li><li class=""><a href="/docs/documentationOverview" target="_self">Documentation</a></li><li class="siteNavGroupActive siteNavItemActive"><a href="/blog/" target="_self">Blog</a></li><li class=""><a href="/careers" target="_self">Careers</a></li><li class=""><a href="/about" target="_self">About</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search..." title="Search..."/></li><li class=""><a href="https://github.com/questdb/questdb" target="_self">GitHub</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Recent Posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Recent Posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/blog/2020/04/02/using-simd-to-aggregate-billions-of-rows-per-second">QuestDB - Using SIMD to aggregate billions of rows per second</a></li><li class="navListItem"><a class="navItem" href="/blog/2020/03/15/interthread">The art of thread messaging</a></li><li class="navListItem"><a class="navItem" href="/blog/2019/12/19/lineprot">What makes QuestDB faster than InfluxDB</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="posts"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/04/02/using-simd-to-aggregate-billions-of-rows-per-second">QuestDB - Using SIMD to aggregate billions of rows per second</a></h1><p class="post-meta">April 2, 2020</p><div class="authorBlock"><p class="post-authorName"><a target="_blank" rel="noreferrer noopener">Tancrede Collard</a></p></div></header><article class="post-content"><div><span><p><a href="https://www.questdb.io/getstarted" target="_blank"><img class="banner-4-2" src="/blog/assets/banner-4-2.png" alt="drawing"/></a></p>
<p><a href="https://en.wikipedia.org/wiki/SIMD" target="_blank">SIMD instructions</a> are specific CPU instruction sets for arithmetic calculations that use synthetic parallelisation.
The parallelisation is synthetic because instead of spreading the work across CPU cores,
SIMD performs vector operations on multiple items using a <strong>single</strong> CPU instruction.
In practice, if you were to add 8 numbers together, SIMD does that in 1 operation instead of 8.
We get compounded performance improvements by combining SIMD with actual parallelisation and spanning the work across CPUs.</p>
<p>QuestDB 4.2 introduces SIMD instructions, which made our aggregations faster by 100x!
QuestDB is available <a href="https://github.com/questdb/questdb">open-source under Apache 2.0</a>. If you like what we do, please consider <b> <a href="https://github.com/questdb/questdb"> following us on Github and starring our project <img class="yellow-star" src="/img/star-yellow.svg"/></a></b></p>
<p>As of now, SIMD operations are available for non-keyed aggregation queries, such as
<code>select sum(value) from table</code>. In future releases, we will extend these to keyed aggregations, for example
<code>select key, sum(value) from table</code> (note the intentional omission of <code>GROUP BY</code>). This will also result in ultrafast
aggregation for time-bucketed queries using <code>SAMPLE BY</code>.</p>
<h3><a class="anchor" aria-hidden="true" id="how-fast-is-it"></a><a href="#how-fast-is-it" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How fast is it?</h3>
<p>To get an idea of how fast aggregations have become, we ran a benchmark against kdb+, which is one of the fastest databases out there.
Coincidentally, their new version 4.0 (released a few days ago) introduces performance improvements through implicit parallelism.</p>
<h4><a class="anchor" aria-hidden="true" id="setup"></a><a href="#setup" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Setup</h4>
<p>We have benchmarked QuestDB against kdb's latest version using 2 different CPUs: the <a href="https://ark.intel.com/content/www/us/en/ark/products/134899/intel-core-i7-8850h-processor-9m-cache-up-to-4-30-ghz.html">Intel 8850H</a>
and the <a href="https://www.amd.com/en/products/cpu/amd-ryzen-9-3900x">AMD Ryzen 3900X</a>. Both databases were running on 4 threads.</p>
<h4><a class="anchor" aria-hidden="true" id="queries"></a><a href="#queries" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Queries</h4>
<table>
<thead>
<tr><th>Test</th><th>Query (kdb+ 4.0)</th><th>Query (QuestDB 4.2)</th></tr>
</thead>
<tbody>
<tr><td>sum of 1Bn doubles <br/> no nulls</td><td>zz:1000000000?1000.0 <br/>\t sum zz</td><td>create table zz as (select rnd_double() d from long_sequence(1000000000)); <br/> select sum(d) from zz;</td></tr>
<tr><td>sum of 1Bn ints</td><td>zz:1000000000?1000i <br/> \t sum zz</td><td>create table zz as (select rnd_int() i from long_sequence(1000000000)); <br/> select sum(i) from zz;</td></tr>
<tr><td>sum of 1Bn longs</td><td>zz:1000000000?1000j <br/>\t sum zz</td><td>create table zz as (select rnd_long() l from long_sequence(1000000000));<br/>select sum(l) from zz;</td></tr>
<tr><td>max of 1Bn doubles</td><td>zz:1000000000?1000.0<br/>\t max zz</td><td>create table zz as (select rnd_double() d from long_sequence(1000000000));<br/>select max(d) from zz;</td></tr>
<tr><td>max of 1Bn longs</td><td>zz:1000000000?1000<br/>\t max zz</td><td>create table zz as (select rnd_long() l from long_sequence(1000000000));<br/>select max(l) from zz;</td></tr>
</tbody>
</table>
<h4><a class="anchor" aria-hidden="true" id="results"></a><a href="#results" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Results</h4>
<p><img src="/blog/assets/bench-kdb-8850h.png" alt="alt-text"></p>
<p><img src="/blog/assets/bench-kdb-3900x.png" alt="alt-text"></p>
<p>The dataset producing the results shown above does not contain NULL values. Interestingly, as soon as the data contains NULL values, kdb+ sum() performance drops while QuestDB sum() query time is unchanged as seen on the chart below.</p>
<table>
<thead>
<tr><th>Test</th><th>Query (kdb+ 4.0)</th><th>Query (QuestDB 4.2)</th></tr>
</thead>
<tbody>
<tr><td>sum of 1Bn doubles <br/>(nulls)</td><td>zz:1000000000?1000.0 <br/>zz:?[zz&lt;100;0Nf;zz]<br/>\t sum zz</td><td>create table zz as (select rnd_double(5) d from long_sequence(1000000000));<br/>select sum(d) from zz;</td></tr>
</tbody>
</table>
<p><img src="/blog/assets/bench-kdb-8850H-sum-null.png" alt="alt-text"></p>
<h4><a class="anchor" aria-hidden="true" id="we-can-improve-this-performance-further"></a><a href="#we-can-improve-this-performance-further" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>We can improve this performance further</h4>
<p>QuestDB's sum(int) result is 64-bit long, whereas kdb+ sum(int) returns a 32-bit integer (even if the sum overflows).
Our approach is currently slightly more complicated as we convert each 32-bit integer to a 64-bit long to avoid overflow.
By removing this overhead and more, there is scope left to make our implementation faster in the future.</p>
<h3><a class="anchor" aria-hidden="true" id="perspectives-on-performance"></a><a href="#perspectives-on-performance" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Perspectives on performance</h3>
<p>The execution times outlined above become more interesting once put into context.
This is how QuestDB compares to Postgres when doing a sum of 1 billion numbers from a given table <code>select sum(d) from 1G_double_nonNull</code>.</p>
<p><img src="/blog/assets/bench-pg-kdb-quest.png" alt="alt-text"></p>
<p>We found that our performance figures are constrained by the available memory channels. Both the 8850H and the 3900X
have 2 memory channels, and throwing more than 4 cores at the query above does not improve the performance.
On the other hand, if the CPU has more memory channels, then performance scales almost linearly for both kdb+ and QuestDB.</p>
<p>To get an idea of the impact of memory channels, we spun off a m5.metal instance on AWS. This instance has two
24-core Intel 8275CL with 6 memory channels each. Here are the results compared to the 2-channel 3900X:</p>
<table>
<thead>
<tr><th>cpu cores</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th></tr>
</thead>
<tbody>
<tr><td>8275CL</td><td>910</td><td>605</td><td>380</td><td>240</td><td>193</td><td>176</td><td>156</td><td>148</td><td>140</td><td>136</td><td>133</td><td>141</td></tr>
<tr><td>3900X</td><td>621</td><td>502</td><td>381</td><td>260</td><td>260</td><td>260</td><td>260</td><td>260</td><td>260</td><td>260</td><td>260</td><td>260</td></tr>
</tbody>
</table>
<p>We plot those results below on the left. On the right-hand side, we normalise the results for each CPU and plot the performance
improvement of going from 1 to more cores.</p>
<p><img src="/blog/assets/core-scale.png" alt="alt-text"></p>
<p>Interestingly, the 2-channel 3900X, is much faster on 1 core than the
8275CL. But it does not scale well and hits a performance ceiling at 4 cores. This is because it only has 2 memory channels
that are already saturated. The 6-channel 8275CL allows QuestDB to
scale almost linearly as we add more CPU cores and hits a performance ceiling at around 12 cores.</p>
<p>Unfortunately AWS CPUs are hyperthreaded.
We could unpack even more performance if CPU were fully isolated to run the computations.</p>
<p>We did not get our hands on CPUs with more memory channels for this test, but if you have easy access to 8 or 12-channel servers and would like to benchmark QuestDB, we'd love to hear the results.
You can <a href="https://www.questdb.io/getstarted">download QuestDB</a> and leave a <a target="_blank" href="https://github.com/questdb/questdb/issues/146">comment on github</a></p>
<h3><a class="anchor" aria-hidden="true" id="what-is-next"></a><a href="#what-is-next" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is next?</h3>
<p>In further releases, we will roll out this functionality to other parts of our SQL implementation. QuestDB implements SIMD in a generic fashion, which will allow us to continue adding SIMD to about everything our SQL engine does, such as keyed aggregations, indexing etc. We will also keep improving QuestDB's performance. Through some further work on assembly, we estimate that we can gain another 15% speed on these
operations. In the meantime, if you want to know exactly how we have achieved this, all of our code is <strong><a href="https://github.com/questdb/questdb">open-source</a></strong>!</p>
<h3><a class="anchor" aria-hidden="true" id="about-the-release-questdb-42"></a><a href="#about-the-release-questdb-42" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>About the release: QuestDB 4.2</h3>
<h4><a class="anchor" aria-hidden="true" id="summary"></a><a href="#summary" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Summary</h4>
<p>We have implemented SIMD-based vector execution of queries, such as <code>select sum(value) from table</code>.
This is ~100x faster than non-vector based execution. This is just the beginning as we will introduce vectors to more operations going forward.
Try our first implementation in this release - stay tuned for more features in the upcoming releases!</p>
<h4><a class="anchor" aria-hidden="true" id="important"></a><a href="#important" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Important</h4>
<p>Metadata file format has been changed to include a new flag for columns of type symbol.
It is necessary to convert existing tables to new format. Running the following sql: <code>repair table myTable</code> will update the table metadata.</p>
<h4><a class="anchor" aria-hidden="true" id="what-is-new"></a><a href="#what-is-new" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is new?</h4>
<ul>
<li>Java: vectorized sum(), avg(), min(), max() for DOUBLE, LONG, INT</li>
<li>Java: select distinct symbol optimisation</li>
<li>FreeBSD support</li>
<li>Automatically restore data consistency and recover from partial data loss.</li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="what-we-fixed"></a><a href="#what-we-fixed" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What we fixed</h4>
<ul>
<li>SQL: NPE when parsing SQL text with malformed table name expression , for example ')', or ', blah'</li>
<li>SQL: parsing 'fill' clause in sub-query context was causing unexpected syntax error (#115)</li>
<li>SQL: possible internal error when ordering result of group-by or sample-by</li>
<li>Data Import: Ignore byte order marks (BOM) in table names created from an imported CSV (#114)</li>
<li>SQL: 'timestamp' propagation thru group-by code had issues. sum() was tripping over null values. Added last() aggregate function. (#113)</li>
<li>LOG: make service log names consistent on windows (#106)</li>
<li>SQL: deal with the following syntax 'select * from select ( select a from ....)'</li>
<li>SQL: allow the following syntax 'case cast(x as int) when 1 then ...'</li>
<li>fix(griffin): syntax check for &quot;case&quot;-')' overlap, e.g. &quot;a + (case when .. ) end&quot;</li>
</ul>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2020/03/15/interthread">The art of thread messaging</a></h1><p class="post-meta">March 15, 2020</p><div class="authorBlock"><p class="post-authorName"><a target="_blank" rel="noreferrer noopener">Vlad Ilyushchenko</a></p></div></header><article class="post-content"><div><span><h3><a class="anchor" aria-hidden="true" id="introduction"></a><a href="#introduction" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Introduction</h3>
<p><img src="/blog/assets/threadmessaging.png" alt="drawing" width="480px"/></p>
<p>Inter-thread messaging is a fundamental part of any asynchronous system. It is the component responsible for transportation of data between threads. Messaging forms the infrastructure, the scaffolding of multi-threaded application and just like real-world transport infrastructure we want it to be inexpensive, fast, reliable and clean.</p>
<p>For QuestDB we wrote our own messaging and this post is about how it works and how fast it is.</p>
<div></div>
<h3><a class="anchor" aria-hidden="true" id="architecture"></a><a href="#architecture" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Architecture</h3>
<p>Borrowing heavily from world-famous Disruptor our messaging revolves around multiple threads accessing shared circular data structure. We call it RingQueue. Semantically RingQueue provides unbounded, index-based, random access to its elements. It does not coordinate concurrent access nor does it provide guarantees on thread safety. Coordination and thread-safety is a concern of Sequences. Sequences are responsible for providing indices that can be used to access RingQueue concurrently and safely.</p>
<p>To help sequences do their magic they have to be shaped into a graph. We start with syntax to chain sequences together:</p>
<p><code>a.then(b).then(c).then(d)</code></p>
<p>The result is a trivial sequence graph:</p>
<p><code>a -&gt; b -&gt; c -&gt; d</code></p>
<p>To branch we use helper class FanOut:</p>
<p><code>a.then(FanOut.to(b).and(c)).then(d)</code></p>
<p>The result is this sequence graph:</p>
<pre><code class="hljs css language-shell script">     +--&gt; B --&gt;+
A --&gt;|         |--&gt; D
     +--&gt; C --&gt;+
</code></pre>
<p>These two pieces of syntax are flexible enough to create any desired flow. This example shows that FanOut can have chain of sequences and other FanOuts:</p>
<p><code>a.then(FanOut.to(FanOut.to(b).and(c)).and(d.then(e)).then(f)</code></p>
<p>It is quite a mouthful but it creates this nice little graph:</p>
<pre><code class="hljs css language-shell script">        +--&gt; B --&gt;+
    +-&gt; |         |
    |   +--&gt; C --&gt;+
<span class="hljs-meta">A--&gt;</span><span class="bash">|             |--&gt; F </span>
    |             |
    +-&gt; D -&gt; E --&gt;+
</code></pre>
<p>FanOut can also be used as a placeholder in a chain to allow threads to subscribe/unsubscribe on the fly. Dynamic subscription is then simply adding a new sequence to FanOut:</p>
<pre><code class="hljs css language-java"><span class="hljs-comment">// You can add as many sequences into fan out as you like.</span>
<span class="hljs-comment">// Sequences can be added either up front or subscribe/unsubscribe on the fly.</span>
FanOut fanOut = <span class="hljs-keyword">new</span> FanOut();

<span class="hljs-comment">// ordinary producer sequence</span>
Sequence seqProducer = <span class="hljs-keyword">new</span> SPSequence(queue.getCapacity());
<span class="hljs-comment">// daisy chain producer and fan out and loop back producer</span>
seqProducer.then(fanOut).then(seqProducer);

<span class="hljs-comment">// meanwhile in another thread ....</span>
...

<span class="hljs-comment">// Add individual consumer sequences later as needed.</span>
<span class="hljs-comment">// This is thread safe non-blocking operation that can be performed from any thread.</span>
<span class="hljs-comment">// It is important to use current producer position as consumer starting point when subscribing on the fly.</span>
Sequence consumer1 = fanOut.addAndGet(<span class="hljs-keyword">new</span> SCSequence(seqProducer.current()));

<span class="hljs-comment">// do something useful with consumer1 sequence</span>
...

<span class="hljs-comment">// remove sequence from fanOut to unsubscribe</span>
fanOut.remove(consumer1);
</code></pre>
<p>Typical graph must contain single producer sequence and one or more consumer sequences. It will also have to be circular, e.g. to start and end with producer sequence. Graph has to be circular because we use circular underlying data structure, RingQueue. Without loop-back producer would be liable to overwrite queue elements before consumers had a chance to read them. Worse still, queue elements can be written to and read from concurrently. We don't want that to happen, right?</p>
<p>To help create practical sequence graph we implemented 4 types of sequences we can play with. These sequences are better understood as combination of their types and properties. SP - single producer, MP - multiple producer, SC - single consumer and MC - multiple consumer. Multi- sequences allow concurrent access and they guarantee that no two threads can retrieve same index. It is this property adds extra fun dimension to sequence graphs. Consider this graph:</p>
<p><code>A -&gt; B -&gt; A</code></p>
<p>or in Java notations:</p>
<p><code>A.then(B).then(A)</code></p>
<p>When &quot;B&quot; is an instance of MCSequence() we have a self-balancing worker pool. When &quot;A&quot; is MPSequence(), we have many-to-many pub-sub system. Cool, eh?</p>
<p>Single- sequences are faster but they are not thread-safe. They should be preferred for single-threaded consumer models.</p>
<p>Lets take a look at how threads interact with sequences. This is a typical example of publisher:</p>
<pre><code class="hljs css language-java"><span class="hljs-comment">// loop until there is work to do</span>
<span class="hljs-comment">// consumer thread may be able to rely on producer to</span>
<span class="hljs-comment">// publish "special" message to indicate end of stream.</span>
<span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) {
  
  <span class="hljs-comment">// Non-blocking call. Method returns immediately either with zero-based</span>
  <span class="hljs-comment">// ring queue index or negative long indicating one of following:</span>
  <span class="hljs-comment">// -1 = queue is empty</span>
  <span class="hljs-comment">// -2 = there was a contest for queue index and this thread has lost</span>
  <span class="hljs-keyword">long</span> cursor = sequence.next();
  <span class="hljs-keyword">if</span> (cursor &lt; <span class="hljs-number">0</span>) {
    <span class="hljs-comment">// negative cursor is an error</span>
    <span class="hljs-comment">// thread has a choice of things to do:</span>
    <span class="hljs-comment">// - busy spin</span>
    <span class="hljs-comment">// - yield/park</span>
    <span class="hljs-comment">// - work on something else</span>
    LockSupport.parkNanos(<span class="hljs-number">1</span>);
    <span class="hljs-keyword">continue</span>;
  }
  
  <span class="hljs-comment">// write to queue</span>
  <span class="hljs-keyword">try</span> {
    queue.get(cursor).value;
  } <span class="hljs-keyword">finally</span> {
    <span class="hljs-comment">// releasing cursor promptly is important</span>
    sequence.done(cursor);
  }
}

</code></pre>
<p><code>Sequence.next()</code> return values are:</p>
<p>-1  Queue is unavailable. It is either full or empty, depending on whether it is producer or consumer sequence</p>
<p>-2  Temporary race condition. Sequence failed CAS and delegated decision to your application.</p>
<p>Consumer sequence interaction is almost identical. The only difference would be consumer reading queue item instead of writing it.</p>
<p>Performance of single-threaded sequences can benefit further from batching. Batching relies on receiving range of indices from sequence and calling done() at end of batch rather than for every queue item. This is what consumer code might look like (producer code is the same):</p>
<pre><code class="hljs css language-java"><span class="hljs-keyword">while</span> (running) {
  <span class="hljs-keyword">long</span> cursor = sequence.next();
  
  <span class="hljs-keyword">if</span> (cursor &lt; <span class="hljs-number">0</span>) {
    LockSupport.parkNanos(<span class="hljs-number">1</span>);
    <span class="hljs-keyword">continue</span>;
  }

  <span class="hljs-comment">// get max index sequence can reach</span>
  <span class="hljs-keyword">long</span> available = sequence.available();
  
  <span class="hljs-comment">// look thru queue elements without using sequence</span>
  <span class="hljs-keyword">while</span> (cursor &lt; available) {
    queue.get(cursor++);
  }
  
  <span class="hljs-comment">// calling done() only once per batch can yield significant performance benefit</span>
  sequence.done(available - <span class="hljs-number">1</span>);
}
</code></pre>
<p>Multi-threaded sequence do not support batches.</p>
<h3><a class="anchor" aria-hidden="true" id="performance"></a><a href="#performance" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Performance</h3>
<p>I used Shipilev's project that already had Disruptor benchmark and I added QuestDB implementation of the same pipeline.</p>
<p>Benchmark source on <strong><a href="https://github.com/bluestreak01/disrupting-fjp">GitHub</a></strong></p>
<p><strong>2 CPU MBP 2015</strong></p>
<pre><code class="hljs css language-shell script">Benchmark          (slicesK)  (threads)  (workMult)  Mode  Cnt    Score    Error  Units
Disruptor.run            500          2          10    ss   50   10.043 ±  0.158  ms/op
Disruptor.run           1000          2          10    ss   50   19.944 ±  0.285  ms/op
Disruptor.run           5000          2          10    ss   50  133.082 ±  6.032  ms/op
QuestdbFanOut.run        500          2          10    ss   50   13.027 ±  0.180  ms/op
QuestdbFanOut.run       1000          2          10    ss   50   26.329 ±  0.327  ms/op
QuestdbFanOut.run       5000          2          10    ss   50  141.686 ±  4.129  ms/op
QuestdbWorker.run        500          2          10    ss   50   29.470 ±  0.976  ms/op
QuestdbWorker.run       1000          2          10    ss   50   62.205 ±  3.278  ms/op
QuestdbWorker.run       5000          2          10    ss   50  321.697 ± 12.031  ms/op
</code></pre>
<p><strong>4 CPU x5960 @ 4.2Ghz</strong></p>
<pre><code class="hljs css language-shell script">Benchmark          (slicesK)  (threads)  (workMult)  Mode  Cnt    Score    Error  Units
Disruptor.run            500          4          10    ss   50    6.892 ±  0.654  ms/op
Disruptor.run           1000          4          10    ss   50   10.143 ±  0.623  ms/op
Disruptor.run           5000          4          10    ss   50   54.084 ±  4.164  ms/op
QuestdbFanOut.run        500          4          10    ss   50    6.364 ±  0.197  ms/op
QuestdbFanOut.run       1000          4          10    ss   50   11.454 ±  0.754  ms/op
QuestdbFanOut.run       5000          4          10    ss   50   50.928 ±  3.264  ms/op
QuestdbWorker.run        500          4          10    ss   50   14.240 ±  1.341  ms/op
QuestdbWorker.run       1000          4          10    ss   50   27.246 ±  2.777  ms/op
QuestdbWorker.run       5000          4          10    ss   50  142.207 ± 15.157  ms/op
</code></pre>
<p>Disruptor and QuestDB perform essentially the same.</p>
<h3><a class="anchor" aria-hidden="true" id="how-to-get-it"></a><a href="#how-to-get-it" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How to get it</h3>
<p>Our messaging system is on Maven central as a part of QuestDB. Don't worry about package size though, QuestDB jar weighs in at 3.6MB and has no dependencies. Jump <strong><a href="https://github.com/questdb/questdb/releases">here</a></strong> for version reference.</p>
</span></div></article></div><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/blog/2019/12/19/lineprot">What makes QuestDB faster than InfluxDB</a></h1><p class="post-meta">December 19, 2019</p><div class="authorBlock"><p class="post-authorName"><a target="_blank" rel="noreferrer noopener">Tancrede Collard</a></p></div></header><article class="post-content"><div><span><p>Our background is in low-latency trading. We are obsessed with performance and have always wanted to build the fastest tech out there.</p>
<p>But let’s keep the suspense for a minute and introduce ourselves first. QuestDB is an open-source SQL time-series database. InfluxDB is the current market leader in time-series, and we thought it would only be fair if we had a stab at their ingestion format called <strong>Influx line protocol (“ILP”)</strong> to compare data ingestion performance between QuestDB and InfluxDB.
It would not be an overstatement to say that InfluxDB uses a lot of CPU. We set ourselves to build a receiver for ILP, which stores data faster than InfluxDB while being hardware efficient.</p>
<p>We built QuestDB in zero-GC Java. Hopefully, the Java community will be proud!</p>
<h3><a class="anchor" aria-hidden="true" id="why-ilp"></a><a href="#why-ilp" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why ILP?</h3>
<p>Starting with QuestDB 4.0.4, users can ingest data through ILP to <strong>leverage SQL to query Influx data alongside other tables in a relational database while keeping the flexibility of ILP</strong>.</p>
<p><img src="/blog/assets/storeasmany.png" alt="alt-text"></p>
<blockquote>
<p>Store (fast) as many — query fast) as one.</p>
</blockquote>
<h3><a class="anchor" aria-hidden="true" id="data-loss-over-udp"></a><a href="#data-loss-over-udp" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Data loss over UDP</h3>
<p>We have conducted our testing over UDP, thus expecting some level of data loss. However, we did not anticipate that InfluxDB would lose so much.</p>
<p>We have built a sender, which caches outgoing messages in a small buffer before sending them to a UDP socket. It sends data as fast as possible to eventually overpower the consumers and introduce packet loss. To test for different use cases, we have throttled the sender by varying the size of its buffer. A smaller buffer results in more frequent network calls and results in lower sending rates.</p>
<p>The benchmark publishes 50 million messages at various speeds. We then measure the number of entries in each DB after the fact to calculate the implied capture rate.</p>
<p>We use the Dell XPS 15 7590, 64Gb RAM, 6-core i9 CPU, 1TB SSD drive. In this experiment, both the sender and QuestDB/InfluxDB instance run on the same machine. UDP publishing is over loopback. OS is Fedora 31, OS UDP buffer size (net.core.rmem_max) is 104_857_600.</p>
<h3><a class="anchor" aria-hidden="true" id="it-comes-down-to-ingestion-speed"></a><a href="#it-comes-down-to-ingestion-speed" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>It comes down to ingestion speed</h3>
<p>Database performance is the bottleneck that results in packet loss. Messages are denied entry, and the loss rate is a direct function of the underlying database speed.</p>
<p>By sending 50m messages at different speeds, we get the following outcome.</p>
<p><img src="/blog/assets/capturerate.png" alt="alt-text"></p>
<blockquote>
<p>Capture rate as a function of sender speed</p>
</blockquote>
<p>InfluxDB’s capture rate rapidly drops below 50%, eventually converging toward single-digit rates.</p>
<p><img src="/blog/assets/captureratechart.png" alt="alt-text"></p>
<blockquote>
<p>Capture rate as a function of sending speed.</p>
</blockquote>
<p><img src="/blog/assets/impliedspeed.png" alt="alt-text"></p>
<blockquote>
<p>Implied ingestion speed in function of Sender speed</p>
</blockquote>
<p>QuestDB’s ingestion speed results are obtained through ILP. Our ingestion speed is considerably higher while using our native input formats instead.</p>
<h3><a class="anchor" aria-hidden="true" id="why-is-the-senders-rate-slower-for-influxdb-compared-to-questdb"></a><a href="#why-is-the-senders-rate-slower-for-influxdb-compared-to-questdb" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why is the sender’s rate slower for InfluxDB compared to QuestDB?</h3>
<p>In this test, we run the sender and the DB on the same machine, and it turns out that <strong>InfluxDB slows down our UDP sender by cannibalizing the CPU</strong>. Here is what happens to your CPUs while using InfluxDB:</p>
<p><img src="/blog/assets/cpuinflux.png" alt="alt-text"></p>
<blockquote>
<p>InfluxDB’s CPU usage when serving requests</p>
</blockquote>
<p>When in use, InfluxDB saturates all of the CPU. As a consequence, it slows down any other program running on the same machine.</p>
<h3><a class="anchor" aria-hidden="true" id="questdbs-secret-sauce"></a><a href="#questdbs-secret-sauce" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>QuestDB’s secret sauce</h3>
<p>We maximise the utilization of each CPU, from which we extract as much performance as possible. For the example below, we compared InfluxDB’s ingestion speed using 12 cores to QuestDB using one CPU core only. Despite utilizing one core instead of 12, QuestDB still outperforms InfluxDB significantly.</p>
<p>If spare CPU capacity arises, QuestDB will execute multiple data ingestions in parallel, leveraging multiple CPUs at the same time, but with one key difference; QuestDB uses work-stealing algorithms to ensure every last bit of CPU capacity is used while never being idle. Let us illustrate why this is the case.</p>
<p>Modern network cards have much superior throughput than the single receiver. Being limited to one receiver by design, InfluxDB considerably under-utilizes the network card, which is the limiting factor in the pipeline.
<img src="/blog/assets/queueinflux.png" alt="alt-text"></p>
<blockquote>
<p>All CPU cores open one single receiver that under-utilizes the network card</p>
</blockquote>
<p>Conversely, QuestDB can open parallel receivers (requiring one core each), fully utilizing the network card capabilities.
The following illustration assumes that there would be spare CPU capacity in other cores to be filled. In such a scenario we would get QuestDB utilizing 12 cores, with each one of those being considerably faster than InfluxDB’s combined 12 cores!</p>
<p><img src="/blog/assets/queuequest.png" alt="alt-text"></p>
<blockquote>
<p>Each CPU core opens an independent receiver working in parallel that fully leverages the network card</p>
</blockquote>
<p>Besides ingestion, InfluxDB also saturates the CPU on queries. The current user cannibalizes the whole CPU, while other users have to wait for their turn.
<img src="/blog/assets/userinflux.png" alt="alt-text"></p>
<blockquote>
<p>Users monopolize all CPU cores one after the other</p>
</blockquote>
<p>By contrast, QuestDB uses each core separately, allowing multiple users to query or write concurrently without delay. The performance gap between QuestDB and InfluxDB grows significantly as the number of simultaneous users increases.
<img src="/blog/assets/userquest.png" alt="alt-text"></p>
<blockquote>
<p>Users share CPU cores and are served concurrently, fast. They also use cores to the maximum.</p>
</blockquote>
<h3><a class="anchor" aria-hidden="true" id="get-started"></a><a href="#get-started" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Get started</h3>
<p>QuestDB supports ILP over UDP multicast and unicast sockets. TCP support will follow shortly. You don’t need to change anything in your application. For Telegraf, you can configure the UDP sender for QuestDB’s address and port.</p>
<p>Follow this link to <strong><a href="http://questdb.io/getstarted">download QuestDB</a></strong>. You can also use our <strong><a href="https://github.com/questdb/questdb/blob/master/benchmarks/src/main/java/org/questdb/LineUDPSenderMain.java">sender</a></strong> against QuestDB and InfluxDB to reproduce the experiment.</p>
<p>You can use JOINs while modifying your data structure on the fly and querying it all in SQL.</p>
</span></div></article></div><div class="docs-prevnext"></div></div></div></div></div><footer class="nav-footer" id="footer"><section class="sitemap"><div align="left" class="footersection"><h5>QuestDB</h5><a href="/docs/documentationOverview">Documentation</a><a href="/getstarted">Download</a><a href="/docs/roadmap">Roadmap</a></div><div align="left" class="footersection"><h5>Community</h5><a href="https://stackoverflow.com/questions/tagged/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://join.slack.com/t/questdb/shared_invite/enQtNzk4Nzg4Mjc2MTE2LTEzZThjMzliMjUzMTBmYzVjYWNmM2UyNWJmNDdkMDYyZmE0ZDliZTQxN2EzNzk5MDE3Zjc1ZmJiZmFiZTIwMGY&gt;"> Join Slack </a><a href="https://twitter.com/" target="@QuestDB" rel="noreferrer noopener">Twitter</a></div><div align="left" class="footersection"><h5>More</h5><a href="/blog">Blog</a><a href="https://github.com/questdb/questdb/">GitHub</a><a class="github-button" href="https://github.com/questdb/questdb" data-icon="octicon-star" data-count-href="/questdb/questdb/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><section class="copyright">Copyright © 2020 QuestDB</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
              !function(f,b,e,v,n,t,s)
              {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
              n.callMethod.apply(n,arguments):n.queue.push(arguments)};
              if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
              n.queue=[];t=b.createElement(e);t.async=!0;
              t.src=v;s=b.getElementsByTagName(e)[0];
              s.parentNode.insertBefore(t,s)}(window, document,'script',
              'https://connect.facebook.net/en_US/fbevents.js');
              fbq('init', '648273155994655');
              fbq('track', 'PageView');
                </script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: 'b2a69b4869a2a85284a82fb57519dcda',
                indexName: 'questdb',
                inputSelector: '#search_input_react',
                algoliaOptions: {}
              });
            </script></body></html>